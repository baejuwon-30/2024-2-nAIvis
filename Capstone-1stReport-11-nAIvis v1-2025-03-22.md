# Team-Info
| (1) 과제명 | Elastic Weight Consolidation 기반 Continual Learning을 활용한 Deep Fingerprinting 성능 개선 |
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 11-nAIvis |
| (3) 팀 구성원 | 배주원 (2271031): 리더, *전체적인 실험 및 논문작성 실행을 주도하며, 주요 사항을 최종 결정한다.* <br> 신유진 (2271034): 팀원, *연구 및 실험을 진행하며 특히 보고서, 회의록 등 진행과정 기록을 주도한다.* <br> 이서연 (2276217): 팀원, *연구 및 실험을 진행하며 특히 그래프, 표 등 결과 자료 제작을 주도한다.* |
| (4) 팀 지도교수 | 오세은 교수님 |
| (5) 과제 분류 | 연구 과제 |
| (6) 과제 키워드 | Catastrophic Forgetting, Continual Learning, Deep Fingerprinting |
| (7) 과제 내용 요약 | Deep Fingerprinting은 Tor 네트워크 환경에서 웹사이트 트래픽 패턴을 식별하는 딥러닝 기반 공격 기법이다. 기존 DF 모델은 정적인 데이터셋에서 학습되어 실제 환경에서 발생하는 트래픽 변화에 적응하지 못하고 성능이 급격히 저하되는 한계를 지닌다. 본 프로젝트는 이러한 Catastrophic Forgetting 문제를 해결하고자 Continual Learning 기법 중 하나인 Elastic Weight Consolidation(EWC)을 적용한다. 제안하는 모델은 새로운 트래픽 환경에서도 기존 정보를 유지하며 점진적으로 학습할 수 있어, 실환경 적응성을 높인다. Closed-world와 Open-world 시나리오에서 실험을 수행하여, 기존 모델 대비 성능 유지력과 정확도 향상 정도를 수치로 분석한다. 이 과제는 C.L. 기법의 실제 보안 응용 가능성을 실증하는 데 의의가 있다.

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 |  
Tor 네트워크 사용자는 온라인 익명성을 보호받지만, 웹사이트 핑거프린팅(Website Fingerprinting, WF) 공격은 암호화된 트래픽 패턴을 분석하여 사용자가 방문한 웹사이트를 추론할 수 있는 기법이다. 최근 Deep Learning 기술을 활용한 Deep Fingerprinting(DF) 모델이 등장하면서 WF 공격의 정확도는 크게 향상되었다. 하지만 기존 DF 모델은 한 번에 수집된 정적인 데이터셋으로 학습되며, 시간이 흐르거나 Tor 브라우저가 업데이트될 경우 새로운 트래픽 패턴에 적응하지 못하는 단점이 있다. 이는 성능 저하(Catastrophic Forgetting)를 유발하며, 실시간 환경에서 지속적으로 학습이 필요한 WF 모델의 실용성을 떨어뜨린다. 본 프로젝트는 이러한 문제점을 해결하기 위해 Continual Learning(C.L.) 기법 중 Elastic Weight Consolidation(EWC)을 적용하여, 과거에 학습한 정보의 손실을 최소화하면서도 새로운 정보 학습이 가능하도록 설계된 DF 모델을 제안한다. 이 모델은 Tor 네트워크에서 발생하는 트래픽 변화에 효과적으로 대응할 수 있어, 실환경에서도 안정적으로 높은 성능을 유지할 수 있다는 점에서 실용성과 학술적 의의가 크다. |

| (2) 기존연구와의 비교 |  
기존 Deep Fingerprinting 연구는 Tor 트래픽을 CNN 기반으로 분석하여 웹사이트를 분류하는 방식으로, 높은 정확도를 기록해왔다. 대표적인 DF 모델(예: Sirinam et al.의 DFNet)은 초기에 우수한 성능을 보였지만, 시간이 지남에 따라 변화하는 트래픽 패턴에 적응하지 못하는 한계가 있었다. 이 문제를 해결하기 위해 일부 연구에서는 재학습 또는 Fine-tuning을 제안했으나, 이는 많은 연산 비용과 레이블링 자원을 요구한다. 반면 Continual Learning은 점진적으로 데이터를 받아들이면서도 이전 지식의 손실을 줄이는 접근으로, 재학습 없이도 실시간 대응이 가능하다. 특히 EWC는 기존 파라미터의 중요도를 계산해 손실 함수에 반영함으로써 과거 지식의 보존을 도모하는 방식이다. 본 프로젝트는 기존 연구들과 비교해 **(1)** 시간에 따른 성능 저하 방지, **(2)** 데이터 변경에 유연한 적응성, **(3)** 추가 학습 비용 절감의 장점을 가진다. |

| (3) 제안 내용 |  
본 프로젝트는 Deep Fingerprinting 모델에 Elastic Weight Consolidation(EWC)을 적용한 Continual Learning 기반 프레임워크를 제안한다. 먼저, 기존 DF 모델을 1D-CNN 구조로 구현하고, 트래픽 데이터를 일정 시점 이후 업데이트된 새로운 데이터로 나누어 시나리오를 구성한다. 각 Task마다 모델을 순차적으로 학습시키되, EWC를 통해 중요 가중치가 크게 변하지 않도록 제한한다. 이를 통해 새로운 Task 학습 시 기존 정보의 손실을 방지하고, 누적된 정보를 바탕으로 모델이 점진적으로 개선되도록 유도한다. 실험은 Closed-world (고정된 사이트들에 대한 반복 학습 시나리오)와 Open-world (새로운 사이트가 추가되는 시나리오)로 나누어 진행하며, 각 Task 간 정확도 변화, Catastrophic Forgetting 지표(F), 전체 평균 정확도 등 다양한 수치를 측정하여 기존 모델과 비교 분석한다. |

| (4) 기대효과 및 의의 |  
1. **실환경 적응성 강화**: 변화하는 트래픽 패턴에 지속적으로 적응할 수 있어, 실시간 보안 위협 분석에 적합하다.  
2. **재학습 비용 절감**: 기존 데이터를 모두 재학습하지 않아도 되므로, 계산 자원과 시간의 효율성이 높다.  
3. **보안 연구에서의 CL 적용 사례 제시**: 지금까지 대부분 이미지나 자연어 처리에서 사용된 Continual Learning 기법을 정보보안 분야에 적용한 첫 시도 중 하나로 학술적 기여 가능성이 크다.  
4. **실험적 타당성 확보**: 다양한 환경에서 실험을 진행하여 실제 응용 가능성을 검증함으로써, 향후 시스템 보안 제품화의 기반이 될 수 있다. |

| (5) 주요 기능 리스트 |  
- **1. Deep Fingerprinting 기본 모델 구현**:  
    - Tor 트래픽 시퀀스를 입력으로 받아 CNN 기반 구조를 통해 웹사이트 분류  
- **2. EWC 적용 모듈 설계**:  
    - 각 파라미터의 Fisher Information을 계산하고 중요도를 기반으로 손실 함수에 규제항 추가  
- **3. 학습 Task 분할 및 자동화**:  
    - 연속된 Task들을 구성하여 모델이 순차적으로 학습되도록 환경 구성 및 스크립트 자동화  
- **4. 성능 평가 모듈 구현**:  
    - Accuracy, Forgetting Rate, Average Accuracy 등 C.L. 분야의 성능 지표 산출 및 비교  
- **5. 시각화 도구 개발**:  
    - 실험 결과를 시간 흐름에 따라 선형 그래프, 막대 그래프 등으로 시각화하여 분석 지원

<br>

# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 |  
- **기능적 요구사항**:  
    - DF 모델 구현, EWC 모듈 통합, Task 자동 전환, 정확도 및 Forgetting 수치 계산, 시각화 결과 출력  
- **비기능적 요구사항**:  
    - 학습 효율성 확보 (한 Task당 학습 시간 30분 이내), 정확도 85% 이상 유지, CLI 기반 학습 제어  
- **유스케이스**:  
    - 사용자(Tor 트래픽 분석자)는 지속적으로 변화하는 트래픽 환경에서도 매번 전체 재학습 없이 모델을 업데이트할 수 있어야 하며, 이전 학습 내용은 유지되어야 한다.  
- **설계 도구**:  
    - Python 3.x, PyTorch, NumPy, Matplotlib, Scikit-learn, Wireshark, Tor Browser, Tranco Dataset 사용 |

| (2) 전체 시스템 구성 |  
시스템은 다음과 같은 5가지 주요 모듈로 구성됨:  
1. **트래픽 수집 및 전처리 모듈**  
    - Tor 환경에서 트래픽 캡처 후, 패킷 시퀀스로 변환 및 정규화  
2. **기본 DF 모델 학습 모듈**  
    - 1D-CNN 구조로 구성된 모델에서 초기 Task 학습  
3. **EWC 기반 Continual Learning 모듈**  
    - 파라미터 중요도 계산 (Fisher Information) → 손실함수에 규제항 추가  
4. **Task 매니저 및 실험 제어 모듈**  
    - 각 Task 간 학습 전환을 자동화하고 실험 로그 기록  
5. **성능 분석 및 시각화 모듈**  
    - 정확도, Forgetting, Average Accuracy 등 계산 후 시각화  

외부 사용 도구: Tor Browser, tcpdump, Wireshark, Tranco 사이트 리스트, PyTorch 기반 학습 파이프라인 |

| (3) 주요엔진 및 기능 설계 |  
- **DF 모델 (1D-CNN)**  
    - 입력: 5000 길이의 패킷 방향 시퀀스  
    - 구조: Conv1d → ReLU → MaxPool → Conv1d → ReLU → MaxPool → Flatten → FC → Softmax  
    - 목적: 웹사이트 분류 정확도 극대화  
- **EWC 손실함수 설계**  
    - L_total = L_current + λ ∑(F_i * (θ_i - θ*_i)^2)  
    - F_i: 이전 Task에서 계산된 Fisher Information  
    - θ*_i: 이전 Task에서의 최적 파라미터  
    - λ: 중요도 조절 하이퍼파라미터  
- **성능 평가 방식**  
    - Task 별 Accuracy, Forgetting Rate, Final Accuracy 측정 및 비교  
    - 데이터 변화가 있는 실험에서 지속 학습 모델의 성능 유지력 비교 |

| (4) 주요 기능의 구현 |  
1. **EWC 구현 및 적용**  
    - PyTorch 기반으로 각 파라미터의 중요도를 저장하고, 이후 학습 시 손실 함수에 규제 항으로 반영  
2. **실험 자동화 스크립트**  
    - Task 리스트 기반으로 학습/평가 과정을 루프 구조로 구현하여, 여러 시나리오를 반복 평가 가능하도록 설계  
3. **시각화**  
    - 각 Task 간 Accuracy 변화, Forgetting 수치 등 결과를 matplotlib을 통해 그래프 출력 |

| (5) 기타 |  
- 향후 실험 결과를 바탕으로 다른 C.L. 기법(EWC-O, SI 등)과의 비교 실험 예정  
- 국내 보안 학회(KCC) 논문 제출을 목표로 논문 구조 및 그림 구성도 병행 작업 중  
- 5월 초까지 Task-IL 시나리오 실험 완료 및 논문 초안 완성을 목표로 일정 조율 중 |
