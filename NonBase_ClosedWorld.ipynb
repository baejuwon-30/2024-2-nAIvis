{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook에서 출력 생략을 방지\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import utility\n",
    "import Model\n",
    "import EWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from EWC import evaluate\n",
    "from utility import LoadDataNoDefCW_EWC\n",
    "from Model import DFNet\n",
    "import random\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adamax\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only CPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "description = \"Training and evaluating DF model for closed-world scenario on non-defended dataset\"\n",
    "\n",
    "print(description)\n",
    "# Training the DF model\n",
    "NB_EPOCH = 30   # Number of training epoch\n",
    "print (\"Number of Epoch: \", NB_EPOCH)\n",
    "BATCH_SIZE = 128 # Batch size\n",
    "VERBOSE = 2 # Output display mode\n",
    "LENGTH = 10000 # Packet sequence length\n",
    "OPTIMIZER = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) # Optimizer\n",
    "\n",
    "NB_CLASSES = 95 # number of outputs = number of classes\n",
    "INPUT_SHAPE = (LENGTH,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: shuffled and split between train and test sets\n",
    "print (\"Loading and preparing data for training, and evaluating the model\")\n",
    "X_A_train, X_B_train, y_A_train, y_B_train, X_A_test, X_B_test, y_A_test, y_B_test = LoadDataNoDefCW_EWC()\n",
    "# Please refer to the dataset format in readme\n",
    "K.set_image_data_format(\"channels_last\") # tf is tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and training model\n",
    "print (\"Building and training DF model\")\n",
    "\n",
    "model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "print (\"Model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjust the sequence length to a target length\n",
    "def adjust_sequence_length(sequence, target_length=10000, padding_value=-1):\n",
    "    if len(sequence) < target_length:\n",
    "        # If the sequence is shorter than the target length, pad with the specified value\n",
    "        sequence = sequence + [padding_value] * (target_length - len(sequence))\n",
    "    else:\n",
    "        # If the sequence is longer than the target length, truncate it\n",
    "        sequence = sequence[:target_length]\n",
    "    return sequence\n",
    "\n",
    "# Adjust sequence lengths for each dataset\n",
    "X_A_train = np.array([adjust_sequence_length(seq) for seq in X_A_train])\n",
    "X_B_train = np.array([adjust_sequence_length(seq) for seq in X_B_train])\n",
    "X_A_test = np.array([adjust_sequence_length(seq) for seq in X_A_test])\n",
    "X_B_test = np.array([adjust_sequence_length(seq) for seq in X_B_test])\n",
    "\n",
    "# Convert data to float32 type\n",
    "X_A_train = X_A_train.astype('float32')\n",
    "X_A_test = X_A_test.astype('float32')\n",
    "X_B_train = X_B_train.astype('float32')\n",
    "X_B_test = X_B_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a [Length x 1] x n shape as input to the DF CNN (Tensorflow)\n",
    "X_A_train = X_A_train[:, :,np.newaxis]\n",
    "X_A_test = X_A_test[:, :,np.newaxis]\n",
    "X_B_train = X_B_train[:, :,np.newaxis]\n",
    "X_B_test = X_B_test[:, :,np.newaxis]\n",
    "\n",
    "print(X_A_train.shape[0], 'train samples')\n",
    "print(X_A_test.shape[0], 'test samples')\n",
    "print(X_B_train.shape[0], 'train samples')\n",
    "print(X_B_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to categorical classes matrices\n",
    "y_A_train = np_utils.to_categorical(y_A_train, NB_CLASSES)\n",
    "y_A_test = np_utils.to_categorical(y_A_test, NB_CLASSES)\n",
    "y_B_train = np_utils.to_categorical(y_B_train, NB_CLASSES)\n",
    "y_B_test = np_utils.to_categorical(y_B_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_A_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = DFNet.build(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "# A 데이터로 학습\n",
    "model.fit(X_A_train, y_A_train, batch_size=BATCH_SIZE, epochs=100, verbose=VERBOSE)\n",
    "\n",
    "# A 데이터 평가\n",
    "print(\"Accuracy on Task A after training on Task A:\")\n",
    "print(evaluate(model, X_A_test, y_A_test))\n",
    "\n",
    "# B 데이터로 추가 학습 (같은 모델)\n",
    "model.fit(X_B_train, y_B_train, batch_size=BATCH_SIZE, epochs=100, verbose=VERBOSE)\n",
    "\n",
    "# B 데이터 평가\n",
    "print(\"Accuracy on Task B after training on Task B:\")\n",
    "print(evaluate(model, X_B_test, y_B_test))\n",
    "\n",
    "# A 데이터로 재평가\n",
    "print(\"Accuracy on Task A after training on Task B:\")\n",
    "print(evaluate(model, X_A_test, y_A_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nAIvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
